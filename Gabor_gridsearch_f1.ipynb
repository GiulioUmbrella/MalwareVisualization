{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yly-YXkcww2F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBKCp-ltww2R"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "X = np.load('/home/filsave/malviso/X.npy', allow_pickle=True)\n",
        "y = np.load('/home/filsave/malviso/y.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZGXYMTNww2Y"
      },
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVEDZbUdww2d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def gabor_filter(ksize, sigma, theta, lambd, gamma, psi):\n",
        "    filter_kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, cv2.CV_32F)\n",
        "    return filter_kernel\n",
        "\n",
        "def apply_gabor_filter(img, filter_kernel):\n",
        "    filtered_img = cv2.filter2D(img, cv2.CV_8UC3, filter_kernel)\n",
        "    return filtered_img\n",
        "\n",
        "def extract_features(filtered_img):\n",
        "    mean = np.mean(filtered_img)\n",
        "    var = np.var(filtered_img)\n",
        "    feature_vector = np.concatenate((np.array([mean]), np.array([var])))\n",
        "    return feature_vector\n",
        "\n",
        "def Gabor_filter_extraction(img):\n",
        "    # Define the parameters for the 24 Gabor filters\n",
        "    ksize = 5\n",
        "    sigma_list = [1, 2, 3]\n",
        "    theta_list = [0, np.pi/8, np.pi/4, 3*np.pi/8]\n",
        "    lambd_list = [0.05, 0.25]\n",
        "    gamma = 0.5\n",
        "    psi = 0.0\n",
        "\n",
        "    filtered_img_list = []\n",
        "    for sigma in sigma_list:\n",
        "        for theta in theta_list:\n",
        "            for lambd in lambd_list:\n",
        "                # Create the filter kernel\n",
        "                filter_kernel = gabor_filter(ksize, sigma, theta, lambd, gamma, psi)\n",
        "                # Apply the filter to the image\n",
        "                filtered_img = apply_gabor_filter(img, filter_kernel)\n",
        "                filtered_img_list.append(filtered_img)\n",
        "    feature_vector = []\n",
        "    for i, filtered_img in enumerate(filtered_img_list):\n",
        "      filtered_img = cv2.normalize(filtered_img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
        "      features = extract_features(filtered_img)\n",
        "      feature_vector.append(features)\n",
        "\n",
        "    hist = cv2.calcHist([img], [0], None, [16], [0, 256])\n",
        "    feature_vector.append(hist)\n",
        "    return feature_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ_44WUJww2l"
      },
      "outputs": [],
      "source": [
        "total_des_test = [Gabor_filter_extraction(img) for img in X_test] \n",
        "\n",
        "total_des_train = [Gabor_filter_extraction(img) for img in X_train] \n",
        "\n",
        "# reshape the filters\n",
        "tot_train_features = []\n",
        "\n",
        "for i in total_des_train:\n",
        "  x = np.hstack(i[:24])\n",
        "  z = i[-1].flatten()\n",
        "  w = np.concatenate((x,z))\n",
        "  tot_train_features.append(w)\n",
        "\n",
        "\n",
        "tot_test_features = []\n",
        "\n",
        "for i in total_des_test:\n",
        "  x = np.hstack(i[:24])\n",
        "  z = i[-1].flatten()\n",
        "  w = np.concatenate((x,z))\n",
        "  tot_test_features.append(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdXr-cLXww2r"
      },
      "outputs": [],
      "source": [
        "tot_train_features = np.array(tot_train_features)\n",
        "\n",
        "tot_test_features = np.array(tot_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-I5AjTJww2v"
      },
      "outputs": [],
      "source": [
        "#clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "#clf.fit(tot_train_features, y_train)\n",
        "#score = clf.score(tot_test_features, y_test)\n",
        "#print(\" Test accuracy: \", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P45QLxTpww2z"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the parameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 4, 8],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create an instance of the RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create an instance of GridSearchCV\n",
        "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=10, scoring=f1_scorer)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(tot_train_features, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Get the best classifier\n",
        "best_clf = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdAz3h4Uww25",
        "outputId": "c39115a1-4f8b-4d82-a362-0fa4fc2ec762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9070146818923328\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Predict using the best classifier\n",
        "y_pred = best_clf.predict(tot_test_features)\n",
        "\n",
        "# Calculate the accuracy of the predictions\n",
        "f1_accuracy = f1_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", f1_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q82VcXL7ww2-",
        "outputId": "64cf1deb-f4d8-4967-a518-5fe4910a892f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'max_depth': None,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 300}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E85LgE7ww3C",
        "outputId": "d4de5a57-2725-412d-9437-f209f667bba9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_clf"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}